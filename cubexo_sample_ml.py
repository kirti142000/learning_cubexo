# -*- coding: utf-8 -*-
"""cubexo_sample_ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PfxkmwEfbgaYSeiwEa4amVJNAvjn6L4o
"""

import numpy as np
import pandas as pd

from google.colab import drive


# Mount Google Drive
drive.mount('/content/drive')

# Load the CSV file from your Google Drive
file_path = '/content/drive/My Drive/system.csv'  # Update with your file path
df = pd.read_csv(file_path)

# Drop columns with more than 90% missing values
df = df.dropna(axis=1, thresh=int(0.1 * len(df)))

# Fill remaining missing values
df = df.fillna(0)  # Fill missing values with 0 or use df.mean() for numerical columns

# Drop irrelevant columns (e.g., text columns, IDs)
columns_to_drop = [ 'description', 'finalized_at','deleted_at','access_rights','manager_id','modifier_id','reserved_by_id','file_name','reference_id','url']
df_clean_data = df.drop(columns=[col for col in columns_to_drop if col in df.columns])

print("Shape after cleaning:", df.shape)

df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')
df['updated_at'] = pd.to_datetime(df['updated_at'], errors='coerce')

# Step 3: Create a new feature: time difference in minutes
df['time_diff_minutes'] = (df['updated_at'] - df['created_at']).dt.total_seconds() / 60

# Step 4: Drop rows with missing values in required columns
df_clean = df[['time_diff_minutes', 'is_final']].dropna()

# Step 5: Define X and y
X = df_clean[['time_diff_minutes']]
y = df_clean['is_final'].astype(int)

df_clean

# Filter and view directly
df[df['is_final'] == True].head()

from sklearn.preprocessing import StandardScaler

# Scale the features (time_diff_minutes)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("Scaled Features: ", X_scaled[:5])  # Preview scaled features

from sklearn.model_selection import train_test_split

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

print(f"Training data size: {len(X_train)}")
print(f"Test data size: {len(X_test)}")

from sklearn.ensemble import RandomForestClassifier

# Initialize and train the Random Forest model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report

# Evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

# Detailed classification report
print("Classification Report:\n", classification_report(y_test, y_pred))

# Use class weight to balance the model
model_balanced = RandomForestClassifier(class_weight='balanced', random_state=42)
model_balanced.fit(X_train, y_train)

# Predict on the test set
y_pred_balanced = model_balanced.predict(X_test)

# Evaluate the balanced model
accuracy_balanced = accuracy_score(y_test, y_pred_balanced)
print(f"Balanced Model Accuracy: {accuracy_balanced:.4f}")

# Create a new sample with time_diff_minutes
sample = pd.DataFrame({'time_diff_minutes': [4.911200]})

# Scale the sample using the same scaler
sample_scaled = scaler.transform(sample)

# Predict the is_final for the new sample
prediction = model.predict(sample_scaled)
print(f"Predicted is_final for minutes: {prediction[0]}")  # 0 or 1